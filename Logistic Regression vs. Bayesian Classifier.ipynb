{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "library(mvtnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "train<-read.csv(\"Task1E_train.csv\")\n",
    "test<-read.csv(\"Task1E_test.csv\")\n",
    "train.data <- train[,-3]\n",
    "train.label <- train[,3]\n",
    "test.data <- test[,-3]\n",
    "test.label <- test[,3]\n",
    "\n",
    "# length of training and testing data\n",
    "train.len <- nrow(train.data)\n",
    "test.len <- nrow(test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Classifier function\n",
    "# c0 and c1 are the types of labels\n",
    "bf <- function(train.data,train.label,test.data,test.label,c0,c1){\n",
    "    \n",
    "    # estimated probability of each label type\n",
    "    p0.hat <- sum(train.label==c0) / nrow(train.data)\n",
    "    p1.hat <- sum(train.label==c1) / nrow(train.data)\n",
    "    \n",
    "    # estimated mean of each label type\n",
    "    # colMeans find the mean of each column\n",
    "    mu0.hat <- colMeans(train.data[train.label==c0,])\n",
    "    mu1.hat <- colMeans(train.data[train.label==c1,])\n",
    "    \n",
    "    # counting the number of each label in subset\n",
    "    # because for example in th efirst 5 rows of training date, there is only one -1 label\n",
    "    # hence, manually setting the variance to 0, else it will return NaN\n",
    "    count1<-0\n",
    "    count2<-0\n",
    "    for (i in train.label){\n",
    "        if (i==1){\n",
    "            count1<-count1+1\n",
    "                }\n",
    "        if(i==-1){\n",
    "            count2<-count2+1\n",
    "                }}\n",
    "\n",
    "    if (count1 <= 1){\n",
    "        sigma0.hat<-0}\n",
    "    \n",
    "    if (count1 > 1){\n",
    "        sigma0.hat <- var(train.data[train.label==c0,])}\n",
    "\n",
    "    \n",
    "    if (count2 <= 1){\n",
    "        sigma1.hat<-0}\n",
    "    \n",
    "    if (count2 > 1){\n",
    "        sigma1.hat <- var(train.data[train.label==c1,])}\n",
    "\n",
    "                        \n",
    "    # covariance matrix\n",
    "    sigma.hat <- p0.hat * sigma0.hat + p1.hat * sigma1.hat\n",
    "                        \n",
    "    # posterior values of each class according to naive bayes\n",
    "    posterior0 <- p0.hat*dmvnorm(x=test.data, mean=mu0.hat, sigma=sigma.hat)\n",
    "    posterior1 <- p1.hat*dmvnorm(x=test.data, mean=mu1.hat, sigma=sigma.hat)\n",
    "                        \n",
    "    # predicting the label from the concept of naive bayes\n",
    "    test.predict <- ifelse(posterior0 > posterior1, c0, c1)\n",
    "                        \n",
    "    # misclassification error\n",
    "    test.error <- sum(test.label!=test.predict)/nrow(train.data) *100\n",
    "    \n",
    "    # error\n",
    "    return(test.error)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty data frame for errors\n",
    "error <- data.frame()\n",
    "# index position of the error dataframe\n",
    "indx = 1\n",
    "\n",
    "for (i in 1:500){\n",
    "    # initializing the current index position of each subset which is 1\n",
    "    j<-1\n",
    "    \n",
    "    # break if 500^th index reached\n",
    "    if (i==500){\n",
    "        break\n",
    "    }\n",
    "    \n",
    "    # for the first five data point\n",
    "    if (i==1){        \n",
    "        i<-i+4\n",
    "        # USING THE BC MODEL ON TRAIN AND TEST SETS\n",
    "        re_model_train<-bf(train.data[j:i,],train.label[j:i],train.data[j:i,],train.label[j:i],1,-1)\n",
    "        re_model_test<-bf(train.data[j:i,],train.label[j:i],test.data[j:i,],test.label[j:i],1,-1)\n",
    "        # STORING THE TRAINING AND TESTING ERRORS\n",
    "        error[indx,'size']<-nrow(train.data[j:i,])\n",
    "        error[indx,'train_error']<-re_model_train\n",
    "        error[indx,'test_error']<-re_model_test\n",
    "        indx<-indx+1\n",
    "        next\n",
    "  }\n",
    "        \n",
    "    # for indexes other than 5,10,15,25,.....,455\n",
    "    if (i%%5!=0){\n",
    "        next\n",
    "    }\n",
    "\n",
    "\n",
    "    else{\n",
    "    \n",
    "        i<-i+5    \n",
    "        # USING THE BC MODEL ON TRAIN AND TEST SETS\n",
    "        re_model_train<-bf(train.data[j:i,],train.label[j:i],train.data[j:i,],train.label[j:i],1,-1)\n",
    "        re_model_test<-bf(train.data[j:i,],train.label[j:i],test.data[j:i,],test.label[j:i],1,-1)\n",
    "        # STORING THE TRAINING AND TESTING ERRORS\n",
    "        error[indx,'size']<-nrow(train.data[j:i,])\n",
    "        error[indx,'train_error']<-re_model_train\n",
    "        error[indx,'test_error']<-re_model_test\n",
    "        indx<-indx+1\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "30.4"
      ],
      "text/latex": [
       "30.4"
      ],
      "text/markdown": [
       "30.4"
      ],
      "text/plain": [
       "[1] 30.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-2.5879156901187</li>\n",
       "\t<li>3.33363351240321</li>\n",
       "\t<li>-9.90124026761517</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -2.5879156901187\n",
       "\\item 3.33363351240321\n",
       "\\item -9.90124026761517\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -2.5879156901187\n",
       "2. 3.33363351240321\n",
       "3. -9.90124026761517\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -2.587916  3.333634 -9.901240"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>-1</li>\n",
       "\t<li>-1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item -1\n",
       "\\item -1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -1\n",
       "2. 1\n",
       "3. 1\n",
       "4. -1\n",
       "5. -1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -1  1  1 -1 -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# auxiliary function that predicts class labels\n",
    "predict <- function(w, X, c0, c1){\n",
    "    sig <- sigmoid(w, X)\n",
    "    return(ifelse(sig>0.5, c0,c1))\n",
    "}\n",
    "    \n",
    "# auxiliary function that calculate a cost function\n",
    "cost <- function (w, X, T, c0){\n",
    "    sig <- sigmoid(w, X)\n",
    "    return(sum(ifelse(T==1, 1-sig, sig)))\n",
    "}\n",
    "# Sigmoid function (=p(C1|X))\n",
    "sigmoid <- function(w, x){\n",
    "    return(1.0/(1.0+exp(-w%*%t(cbind(1,x)))))    \n",
    "}\n",
    "log <- function(train.data,train.label,tau.max=1000,eta=0.01,epsilon=0.01){\n",
    "# Initializations\n",
    "tau.max <- 1000 # maximum number of iterations\n",
    "eta <- 0.01 # learning rate\n",
    "epsilon <- 0.01 # a threshold on the cost (to terminate the process)\n",
    "tau <- 1 # iteration counter\n",
    "terminate <- FALSE\n",
    "\n",
    "## Just a few name/type conversion to make the rest of the code easy to follow\n",
    "X <- as.matrix(train.data) # rename just for conviniance\n",
    "T <- ifelse(train.label==1,1,-1) # rename just for conviniance\n",
    "\n",
    "W <- matrix(,nrow=tau.max, ncol=(ncol(X)+1)) # to be used to store the estimated coefficients\n",
    "W[1,] <- runif(ncol(W)) # initial weight (any better idea?)\n",
    "\n",
    "# project data using the sigmoid function (just for convenient)\n",
    "Y <- sigmoid(W[1,],X)\n",
    "\n",
    "costs <- data.frame('tau'=1:tau.max)  # to be used to trace the cost in each iteration\n",
    "costs[1, 'cost'] <- cost(W[1,],X,T, 1)\n",
    "while(!terminate){\n",
    "    # check termination criteria:\n",
    "    terminate <- tau >= tau.max | cost(W[tau,],X,T, 1)<=epsilon\n",
    "    \n",
    "    # shuffle data:\n",
    "    train.index <- sample(1:length(train.data), length(train.data), replace = FALSE)\n",
    "    X <- X[train.index,]\n",
    "    T <- T[train.index]\n",
    "    \n",
    "    # for each datapoint:\n",
    "    for (i in 1:length(train.data)){\n",
    "        # check termination criteria:\n",
    "        if (tau >= tau.max | cost(W[tau,],X,T, 1) <=epsilon) {terminate<-TRUE;break}\n",
    "        \n",
    "        Y <- sigmoid(W[tau,],X)\n",
    "            \n",
    "        # Update the weights\n",
    "        W[(tau+1),] <- W[tau,] - eta * (Y[i]-T[i]) * cbind(1, t(X[i,]))\n",
    "        \n",
    "        # record the cost:\n",
    "        costs[(tau+1), 'cost'] <- cost(W[tau,],X,T, 1)\n",
    "        \n",
    "        # update the counter:\n",
    "        tau <- tau + 1\n",
    "        \n",
    "        # decrease learning rate:\n",
    "        eta = eta * 0.999\n",
    "    }}\n",
    "    w <- W[tau,]\n",
    "    return(w)\n",
    "}\n",
    "\n",
    "w <- log(train.data,train.label,tau.max=1000,eta=0.01,epsilon=0.01)\n",
    "s<-0\n",
    "for (i in 1:500){\n",
    "    if(predict(w,train.data,1,-1)[i]!=train.label[i]){\n",
    "        s<-s+1\n",
    "    }\n",
    "}\n",
    "s/500*100\n",
    "w\n",
    "predict(w,train.data,1,-1)[1:5]\n",
    "train.data[j:i,],train.label[j:i],train.data[j:i,],train.label[j:i],1,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty data frame for errors\n",
    "error_lr <- data.frame()\n",
    "# index position of the error dataframe\n",
    "indx = 1\n",
    "\n",
    "for (i in 1:500){\n",
    "    # initializing the current index position of each subset which is 1\n",
    "    j<-1\n",
    "    \n",
    "    # break if 500^th index reached\n",
    "    if (i==500){\n",
    "        break\n",
    "    }\n",
    "    \n",
    "    # for the first five data point\n",
    "    if (i==1){        \n",
    "        i<-i+4\n",
    "        # USING THE BC MODEL ON TRAIN AND TEST SETS\n",
    "        w <- log(train.data[j:i,],train.label[j:i],tau.max=1000,eta=0.01,epsilon=0.01)\n",
    "        pred_train <- (predict(w,train.data,1,-1)[j:i])\n",
    "        train.error <- sum(test.label[j:i]!=pred_train)/nrow(train.data[j:i,]) *100\n",
    "        pred_test <- (predict(w,test.data,1,-1)[j:i])\n",
    "        test.error <- sum(test.label[j:i]!=pred_test)/nrow(train.data[j:i,]) *100\n",
    "\n",
    "#         STORING THE TRAINING AND TESTING ERRORS\n",
    "        error_lr[indx,'size']<-nrow(train.data[j:i,])\n",
    "        error_lr[indx,'train_error']<-train.error\n",
    "        error_lr[indx,'test_error']<-test.error\n",
    "        indx<-indx+1\n",
    "        next\n",
    "  }\n",
    "        \n",
    "    # for indexes other than 5,10,15,25,.....,455\n",
    "    if (i%%5!=0){\n",
    "        next\n",
    "    }\n",
    "\n",
    "\n",
    "    else{\n",
    "    \n",
    "        i<-i+5    \n",
    "        w <- log(train.data[j:i,],train.label[j:i],tau.max=1000,eta=0.01,epsilon=0.01)\n",
    "        pred_train <- (predict(w,train.data,1,-1)[j:i])\n",
    "        train.error <- sum(test.label[j:i]!=pred_train)/nrow(train.data[j:i,]) *100\n",
    "        pred_test <- (predict(w,test.data,1,-1)[j:i])\n",
    "        test.error <- sum(test.label[j:i]!=pred_test)/nrow(train.data[j:i,]) *100\n",
    "\n",
    "#         STORING THE TRAINING AND TESTING ERRORS\n",
    "        error_lr[indx,'size']<-nrow(train.data[j:i,])\n",
    "        error_lr[indx,'train_error']<-train.error\n",
    "        error_lr[indx,'test_error']<-test.error\n",
    "        indx<-indx+1\n",
    "    }\n",
    "    \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
